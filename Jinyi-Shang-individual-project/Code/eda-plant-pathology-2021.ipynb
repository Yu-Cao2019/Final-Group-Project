{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport os\nimport cv2\n\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import train_test_split\n\nimport albumentations as A","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/plant-pathology-2021-fgvc8/train.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# duplicate","metadata":{}},{"cell_type":"code","source":"df_d = pd.read_csv('../input/jyduplicate/duplicates.csv',header = None)\ndf_d.columns = ['c1','c2']\ndef conbine_du(df_ta,df_d): \n    for x,y in df_d.values:\n        l1,l2 = df_ta[df_ta.image ==x].values[0][1].split(' '),df_ta[df_ta.image ==y].values[0][1].split(' ')\n        labels_co = list(set(l1+l2))\n        delimeter = ' '\n        df_ta.loc[df_ta[df_ta.image ==x].index,'labels'] = delimeter.join(labels_co)\n        df_ta = df_ta.drop(df_ta[df_ta.image ==y].index)\n    return df_ta   \ndf_redu = conbine_du(df,df_d)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ll(x):\n    if x =='frog_eye_leaf_spot rust':\n        return 'rust frog_eye_leaf_spot'\n    if x =='complex rust':\n        return 'rust complex'\n    else:\n        return x\ndf_redu.labels = df_redu.labels.apply(lambda x: ll(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels = df_redu.labels.value_counts().index.tolist()\ndef label_exchange(df):\n    le = LabelEncoder()\n    le.fit(class_labels)\n    df['label_ex'] = le.transform(df.labels.values)\n    return df, le.classes_\n\ndf,class_labels = label_exchange(df_redu)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_redu.to_csv('train_redu.csv',index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_split(phase = 'train',size =0.2):\n    x_train, x_val, y_train, y_val = train_test_split(df.image,df.label_ex,\n                                                      random_state = 42,\n                                                      shuffle=True,\n                                                      test_size=size,\n                                                      stratify =df.label_ex)\n    tar_csv = pd.DataFrame()\n    if phase in ['train']:\n        tar_csv['image'] = x_train\n        tar_csv['label'] = y_train\n    elif phase in ['val']:\n        tar_csv['image'] = x_val\n        tar_csv['label'] = y_val\n    elif phase in ['test']:\n        DIR = '../input/plant-pathology-2021-fgvc8/sample_submission.csv'\n        tar_csv = pd.read_csv(DIR)\n    \n    return tar_csv\n\nTEST_SIZE=0.2\ntrain_csv = data_split(phase = 'train',size =TEST_SIZE)\nval_csv = data_split(phase = 'val',size= TEST_SIZE)\nprint(f'The test size is {TEST_SIZE}\\nThe length of train set is {len(train_csv)}')\nprint(f'The length of validation set is {len(val_csv)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(class_labels)\ntrain_csv.label.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def img_read(strimg,clach = False):\n    root = '../input/plant-pathology-2021-fgvc8/train_images'\n    imgpath =os.path.join(root,strimg)\n    img = cv2.imread(imgpath,cv2.COLOR_BGR2RGB)\n    \n    if clach :\n        img = A.CLAHE(clip_limit=4.0, tile_grid_size=(8,8), p=1)(image = img)['image']\n    return img\n\npre_dict={}\nfor _,row in train_csv.iterrows():\n    if row.label not in pre_dict:\n        pre_dict[row.label] = [row.image]\n    else:\n        pre_dict[row.label]+=[row.image]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(3,4,figsize=(30,20))\ncc =0\nfor i in range(3):\n    for j in range(4):\n        axs[i][j].axis('off')\n        axs[i][j].imshow(img_read(pre_dict[cc][1]))\n        axs[i][j].set_title(class_labels[cc])\n        cc+=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(3,4,figsize=(30,20))\ncc =0\nfor i in range(3):\n    for j in range(4):\n        axs[i][j].axis('off')\n        axs[i][j].imshow(img_read(pre_dict[cc][1],clach =True))\n        axs[i][j].set_title(class_labels[cc])\n        cc+=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://blog.csdn.net/qq_34107425/article/details/107503132 clahe\ndef imgread(strimg,transform = False):\n    root = '../input/plant-pathology-2021-fgvc8/train_images'\n    imgpath =os.path.join(root,strimg)\n    img = cv2.imread(imgpath,cv2.COLOR_BGR2RGB)\n  \n\n    trlst = [   A.HorizontalFlip(p=1),\n                        A.VerticalFlip(p=1),\n                        A.Rotate(p=1),\n        A.Blur(blur_limit=50,p=1),\n                A.ColorJitter(p=1),\n                A.ColorJitter(p=1),\n             #A.ShiftScaleRotate(p=1),\n             A.CLAHE(clip_limit=4.0, tile_grid_size=(8,8), p=1),\n            A.FancyPCA (alpha=1, p=1),\n            #A.Rotate(p=1),\n              #A.RandomSunFlare(p=1), \n             A.RandomFog(p=1), \n              A.RandomBrightness(p=1),\n#              A.RGBShift(p=1), \n              A.RandomSnow(p=1),\n              A.RandomContrast(limit = 0.5,p = 1),\n              A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50)]\n    if transform:\n        for trans in trlst:\n            img2 = trans(image = img)['image']\n        \n            fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(30,20))\n            ax1.axis('off')\n            ax2.axis('off')\n            ax1.imshow(img)\n            ax2.imshow(img2)\n    else:\n        plt.imshow(img)\n        plt.axis('off')\n        plt.show()\n    return img\nzz=imgread(pre_dict[5][3],transform=True)\nzz.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree('./aug_re_img')\nos.mkdir('aug_re_img')\nROOT='./aug_re_img'\ntrain_new =[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(12):\n    print(f'Start to execute {i} class')\n    print('--------------------------------')\n    if i in [3,9]:  #\n        for img_path in tqdm(pre_dict[i]):\n            \n            transform = A.Compose([\n                        A.CLAHE(clip_limit=4.0, tile_grid_size=(8,8), p=0.6),\n                        A.HorizontalFlip(0.5),\n                        A.VerticalFlip(0.5),\n                        A.Rotate(p=0.5),\n                        A.Resize(256,256)])\n\n            img = img_read(img_path)\n            imgor = transform(image = img)['image']\n            newpath = os.path.join(ROOT,img_path)\n            cv2.imwrite(newpath,imgor)\n            train_new.append([img_path,i])\n    if i in [1]:  #\n        for img_path in tqdm(pre_dict[i]):\n            \n            transform = A.Compose(\n                [A.OneOf([\n                A.CLAHE(clip_limit=4.0, tile_grid_size=(8,8), p=1),\n                A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50),\n                A.FancyPCA (alpha=1, p=1)],p=1),\n                A.OneOf([A.HorizontalFlip(p=1),\n                        A.VerticalFlip(p=1),\n                        A.Rotate(p=1),],p=1),  \n                A.Resize(256,256)])\n\n            img = img_read(img_path)\n            imgor = A.Resize(256,256)(image = img)['image']\n            newpath = os.path.join(ROOT,img_path)\n            cv2.imwrite(newpath,imgor)\n            train_new.append([img_path,i])\n    \n            if np.random.randint(1,9)>4:\n                imgtr = transform(image = img)['image']\n                newpath = os.path.join(ROOT,'1$'+img_path)\n                cv2.imwrite(newpath,imgtr)\n                train_new.append(['1$'+img_path,i])\n                \n    if i in [0,6]: #\n        for I in range(4):\n            for img_path in tqdm(pre_dict[i]):\n                transform = A.Compose(\n                [A.OneOf([\n                A.CLAHE(clip_limit=4.0, tile_grid_size=(8,8), p=1),\n                A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50),\n                A.FancyPCA (alpha=1, p=1)],p=1),\n                A.OneOf([A.HorizontalFlip(p=1),\n                        A.VerticalFlip(p=1),\n                        A.Rotate(p=1),],p=1),  \n                A.ShiftScaleRotate(p=1),\n                A.Resize(256,256)])\n\n                img = img_read(img_path)\n                if I ==0:\n                    imgor = A.Resize(256,256)(image = img)['image']\n                    newpath = os.path.join(ROOT,img_path)\n                    cv2.imwrite(newpath,imgor)\n                    train_new.append([img_path,i])\n                else:\n                    if np.random.randint(0,9)>3:\n                        imgtr = transform(image = img)['image']\n                        newpath = os.path.join(ROOT,f'{I}$'+img_path)\n                        cv2.imwrite(newpath,imgtr)\n                        train_new.append([f'{I}$'+img_path,i])\n\n    if i in [4]:\n        for I in range(4):\n            for img_path in tqdm(pre_dict[i]):\n                transform = A.Compose(\n                [A.OneOf([\n                A.CLAHE(clip_limit=4.0, tile_grid_size=(8,8), p=1),\n                A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50),\n                A.FancyPCA (alpha=1, p=1)],p=1),\n                A.OneOf([A.HorizontalFlip(p=1),\n                        A.VerticalFlip(p=1),\n                        A.Rotate(p=1),],p=1),  \n                A.ShiftScaleRotate(p=1),\n                A.Resize(256,256)])\n                \n                img = img_read(img_path)\n        \n                if I ==0:\n                    imgor = A.Resize(256,256)(image = img)['image']\n                    newpath = os.path.join(ROOT,img_path)\n                    cv2.imwrite(newpath,imgor)\n                    train_new.append([img_path,i])\n                else:\n                    imgtr = transform(image = img)['image']\n                    newpath = os.path.join(ROOT,f'{I}$'+img_path)\n                    cv2.imwrite(newpath,imgtr)\n                    train_new.append([f'{I}$'+img_path,i])\n\n    if i in [10]:\n        for I in range(7):\n            for img_path in tqdm(pre_dict[i]):\n                transform = A.Compose(\n                [A.OneOf([\n                A.CLAHE(clip_limit=4.0, tile_grid_size=(8,8), p=1),\n                A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50),\n                 A.RGBShift(p=1),\n                A.FancyPCA (alpha=1, p=1)],p=1),\n                A.OneOf([A.HorizontalFlip(p=1),\n                        A.VerticalFlip(p=1),\n                        A.Rotate(p=1),],p=1),  \n                A.ShiftScaleRotate(p=1),\n                A.Resize(256,256)])\n                \n                img = img_read(img_path)\n        \n                if I ==0:\n                    imgor = A.Resize(256,256)(image = img)['image']\n                    newpath = os.path.join(ROOT,img_path)\n                    cv2.imwrite(newpath,imgor)\n                    train_new.append([img_path,i])\n                else:\n                    imgtr = transform(image = img)['image']\n                    newpath = os.path.join(ROOT,f'{I}$'+img_path)\n                    cv2.imwrite(newpath,imgtr)\n                    train_new.append([f'{I}$'+img_path,i])\n            \n    if i in [2,11]:\n        for I in range(40):\n            for img_path in tqdm(pre_dict[i]):\n                transform = A.Compose(\n                [A.OneOf([\n                A.CLAHE(clip_limit=4.0, tile_grid_size=(8,8), p=1),\n                A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50),\n                 A.RGBShift(p=1),\n                A.ColorJitter(p=1),\n                A.FancyPCA (alpha=1, p=1)],p=1),\n                A.OneOf([A.HorizontalFlip(p=1),\n                        A.VerticalFlip(p=1),\n                        A.Rotate(p=1),],p=1),  \n                A.ShiftScaleRotate(p=1),\n                A.Resize(256,256)])\n\n                img = img_read(img_path)\n                if I ==0:\n                    imgor = A.Resize(256,256)(image = img)['image']\n                    newpath = os.path.join(ROOT,img_path)\n                    cv2.imwrite(newpath,imgor)\n                    train_new.append([img_path,i])\n                else:\n                    if np.random.randint(0,4)<3:\n                        imgtr = transform(image = img)['image']\n                        newpath = os.path.join(ROOT,f'{I}$'+img_path)\n                        cv2.imwrite(newpath,imgtr)\n                        train_new.append([f'{I}$'+img_path,i])\n\n    if i in [7,8]:\n        for I in range(50):\n            for img_path in tqdm(pre_dict[i]):\n                transform = A.Compose(\n                [A.OneOf([\n                A.CLAHE(clip_limit=4.0, tile_grid_size=(8,8), p=1),\n                A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50),\n                 A.RGBShift(p=1),\n                A.ColorJitter(p=1),\n                A.FancyPCA (alpha=1, p=1)],p=1),\n                A.OneOf([A.HorizontalFlip(p=1),\n                        A.VerticalFlip(p=1),\n                        A.Rotate(p=1),],p=1),  \n                A.ShiftScaleRotate(p=1),\n                A.Resize(256,256)])\n\n                img = img_read(img_path)\n                if I ==0:\n                    imgor = A.Resize(256,256)(image = img)['image']\n                    newpath = os.path.join(ROOT,img_path)\n                    cv2.imwrite(newpath,imgor)\n                    train_new.append([img_path,i])\n                else:\n                    if np.random.randint(0,9)<7:\n                        imgtr = transform(image = img)['image']\n                        newpath = os.path.join(ROOT,f'{I}$'+img_path)\n                        cv2.imwrite(newpath,imgtr)\n                        train_new.append([f'{I}$'+img_path,i])\n    if i in [5]:\n        for I in range(60):\n            for img_path in tqdm(pre_dict[i]):\n                transform = A.Compose(\n                [A.OneOf([\n                A.CLAHE(clip_limit=4.0, tile_grid_size=(8,8), p=1),\n                A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50),\n                A.RGBShift(p=1),\n                A.ColorJitter(p=1),\n                A.FancyPCA (alpha=1, p=1)],p=1),\n                A.OneOf([A.HorizontalFlip(p=1),\n                        A.VerticalFlip(p=1),\n                        A.Rotate(p=1),],p=1),  \n                A.ShiftScaleRotate(p=1),\n                A.Resize(256,256)])\n\n                img = img_read(img_path)\n                if I ==0:\n                    imgor = A.Resize(256,256)(image = img)['image']\n                    newpath = os.path.join(ROOT,img_path)\n                    cv2.imwrite(newpath,imgor)\n                    train_new.append([img_path,i])\n                else:\n                    if np.random.randint(0,7)<6:\n                        imgtr = transform(image = img)['image']\n                        newpath = os.path.join(ROOT,f'{I}$'+img_path)\n                        cv2.imwrite(newpath,imgtr)\n                        train_new.append([f'{I}$'+img_path,i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dftrain = pd.DataFrame(train_new,columns=['image','label'])\ndftrain\ndftrain.to_csv('train.csv',index=False)\nval_csv.to_csv('val.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# label exchange","metadata":{}},{"cell_type":"code","source":"\n# df_redu.labels=df_redu.labels.apply(lambda x:x.split(' '))\n# class_labels=list(set(df_redu.labels.sum()))\n# class_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def label_exchange(yarray):\n\n#   le=LabelEncoder()\n#   le.fit(['powdery_mildew', 'rust', 'frog_eye_leaf_spot', 'scab', 'healthy', 'complex'])\n#   output=[]\n\n#   for label in yarray:\n#     trans=le.transform(label)\n#     y=torch.zeros(6, dtype=torch.long).scatter_(dim=0, index=torch.tensor(trans), value=1)\n#     output.append(y.numpy())\n#   return output,le.classes_\n\n# target, class_labels = label_exchange(df_redu.labels)\n\n# for label in class_labels:\n#   df_redu[label] = 0\n\n# df_redu.iloc[:,2:] = target\n# del(df_redu['labels'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# data visualization","metadata":{}},{"cell_type":"code","source":"# fig1, ax1 = plt.subplots()\n# df_redu.iloc[:,1:].sum(axis=0).plot.pie(autopct='%1.1f%%',shadow=True, startangle=90,ax=ax1)\n# ax1.axis(\"equal\")\n# plt.show()\n# sns.heatmap(df_redu.iloc[:,1:].corr(), cmap=\"RdYlBu\", vmin=-1, vmax=1)\n# # looks like there is no correlation between the labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}